@inproceedings{chen2021learning,
      title={Learning Neural Event Functions for Ordinary Differential Equations},
      author={Ricky T. Q. Chen and Brandon Amos and Maximilian Nickel},
      booktitle={ICLR},
      _venue={ICLR},
      year={2021},
      url={https://arxiv.org/abs/2011.03902},
      abstract={
        The existing Neural ODE formulation relies on an explicit
        knowledge of the termination time. We extend Neural
        ODEs to implicitly defined termination criteria
        modeled by neural event functions, which can be
        chained together and differentiated through. Neural
        Event ODEs are capable of modeling discrete
        (instantaneous) changes in a continuous-time system,
        without prior knowledge of when these changes should
        occur or how many such changes should exist. We test
        our approach in modeling hybrid discrete- and
        continuous- systems such as switching dynamical
        systems and collision in multi-body systems, and we
        propose simulation-based training of point processes
        with applications in discrete control.
      }
}

@inproceedings{chen2021neural,
      title={Neural Spatio-Temporal Point Processes}, 
      author={Ricky T. Q. Chen and Brandon Amos and Maximilian Nickel},
      booktitle={ICLR},
      _venue={ICLR},
      year={2021},
      url={https://arxiv.org/abs/2011.04583},
      abstract={
        We propose a new class of parameterizations for spatio-temporal
        point processes which leverage Neural ODEs as a
        computational method and enable flexible,
        high-fidelity models of discrete events that are
        localized in continuous time and space. Central to
        our approach is a combination of recurrent
        continuous-time neural networks with two novel
        neural architectures, i.e., Jump and Attentive
        Continuous-time Normalizing Flows. This approach
        allows us to learn complex distributions for both
        the spatial and temporal domain and to condition
        non-trivially on the observed event history. We
        validate our models on data sets from a wide variety
        of contexts such as seismology, epidemiology, urban
        mobility, and neuroscience.
      }
}

@misc{cohen2020aligning,
      title={Aligning Time Series on Incomparable Spaces},
      author={Samuel Cohen and Giulia Luise and Alexander Terenin and Brandon Amos and Marc Peter Deisenroth},
      year={2020},
      _venue={arXiv},
      url={https://arxiv.org/abs/2006.12648},
      abstract={
        Dynamic time warping (DTW) is a useful method for aligning, comparing
        and combining time series, but it requires them to
        live in comparable spaces. In this work, we consider
        a setting in which time series live on different
        spaces without a sensible ground metric, causing DTW
        to become ill-defined. To alleviate this, we propose
        Gromov dynamic time warping (GDTW), a distance
        between time series on potentially incomparable
        spaces that avoids the comparability requirement by
        instead considering intra-relational geometry. We
        derive a Frank-Wolfe algorithm for computing it and
        demonstrate its effectiveness at aligning, combining
        and comparing time series living on incomparable
        spaces. We further propose a smoothed version of
        GDTW as a differentiable loss and assess its
        properties in a variety of settings, including
        barycentric averaging, generative modeling and
        imitation learning.
      }
}

@misc{amos2020modelbased,
      title={On the model-based stochastic value gradient for continuous reinforcement learning},
      author={Brandon Amos and Samuel Stanton and Denis Yarats and Andrew Gordon Wilson},
      year={2020},
      _venue={arXiv},
      url={https://arxiv.org/abs/2008.12775},
      abstract={
        Model-based reinforcement learning approaches add explicit domain
        knowledge to agents in hopes of improving the
        sample-efficiency in comparison to model-free
        agents. However, in practice model-based methods are
        unable to achieve the same asymptotic performance on
        challenging continuous control tasks due to the
        complexity of learning and controlling an explicit
        world model. In this paper we investigate the
        stochastic value gradient (SVG), which is a
        well-known family of methods for controlling
        continuous systems which includes model-based
        approaches that distill a model-based value
        expansion into a model-free policy. We consider a
        variant of the model-based SVG that scales to larger
        systems and uses 1) an entropy regularization to
        help with exploration, 2) a learned deterministic
        world model to improve the short-horizon value
        estimate, and 3) a learned model-free value estimate
        after the model's rollout. This SVG variation
        captures the model-free soft actor-critic method as
        an instance when the model rollout horizon is zero,
        and otherwise uses short-horizon model rollouts to
        improve the value estimate for the policy update. We
        surpass the asymptotic performance of other
        model-based methods on the proprioceptive MuJoCo
        locomotion tasks from the OpenAI gym, including a
        humanoid. We notably achieve these results with a
        simple deterministic world model without requiring
        an ensemble.
      }
}


@inproceedings{amos2020differentiable,
  title={{The Differentiable Cross-Entropy Method}},
  author={Amos, Brandon and Yarats, Denis},
  booktitle={ICML},
  _venue={ICML},
  year={2020},
  url={https://arxiv.org/abs/1909.12830},
  abstract={
    We study the Cross-Entropy Method (CEM) for the non-convex
    optimization of a continuous and parameterized
    objective function and introduce a differentiable
    variant (DCEM) that enables us to differentiate the
    output of CEM with respect to the objective
    function's parameters. In the machine learning
    setting this brings CEM inside of the end-to-end
    learning pipeline where this has otherwise been
    impossible. We show applications in a synthetic
    energy-based structured prediction task and in
    non-convex continuous control. In the control
    setting we show on the simulated cheetah and walker
    tasks that we can embed their optimal action
    sequences with DCEM and then use policy optimization
    to fine-tune components of the controller as a step
    towards combining model-based and model-free RL.
  }
}

@inproceedings{lambert2020objective,
  title={Objective Mismatch in Model-based Reinforcement Learning},
  author={Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  year={2020},
  booktitle={L4DC},
  _venue={L4DC},
  year={2020},
  url={https://arxiv.org/abs/2002.04523},
  abstract={
  Model-based reinforcement learning (MBRL) has been shown to be a powerful framework for data-efficiently learning control of continuous tasks. Recent work in MBRL has mostly focused on using more advanced function approximators and planning schemes, with little development of the general framework. In this paper, we identify a fundamental issue of the standard MBRL framework--what we call the objective mismatch issue. Objective mismatch arises when one objective is optimized in the hope that a second, often uncorrelated, metric will also be optimized. In the context of MBRL, we characterize the objective mismatch between training the forward dynamics model wrt the likelihood of the one-step ahead prediction, and the overall goal of improving performance on a downstream control task. For example, this issue can emerge with the realization that dynamics models effective for a specific task do not necessarily need to be globally accurate, and vice versa globally accurate models might not be sufficiently accurate locally to obtain good control performance on a specific task. In our experiments, we study this objective mismatch issue and demonstrate that the likelihood of one-step ahead predictions is not always correlated with control performance. This observation highlights a critical limitation in the MBRL framework which will require further research to be fully understood and addressed. We propose an initial method to mitigate the mismatch issue by re-weighting dynamics model training. Building on it, we conclude with a discussion about other potential directions of research for addressing this issue.
  }
}

@article{amos2020QNSTOP,
  title={{{QNSTOP: Quasi-Newton Algorithm for Stochastic Optimization}}},
  author={Brandon Amos and David Easterling and Layne Watson and
    William Thacker and Brent Castle and Michael Trosset},
  journal={},
  _venue={ACM TOMS},
  year={2020},
  keywords={journal},
  url={https://dl.acm.org/doi/10.1145/3374219},
  abstract={
    QNSTOP consists of serial and parallel (OpenMP) Fortran 2003 codes for the
    quasi-Newton stochastic optimization method of Castle and Trosset. For
    stochastic problems, convergence theory exists for the particular
    algorithmic choices and parameter values used in QNSTOP. Both the parallel
    driver subroutine, which offers several parallel decomposition strategies,
    and the serial driver subroutine can be used for stochastic optimization or
    deterministic global optimization, based on an input switch. QNSTOP is
    particularly effective for “noisy” deterministic problems, using only
    objective function values. Some performance data for computational systems
    biology problems is given.
  }
}


@inproceedings{amos2019differentiable3,
  title={{Differentiable Convex Optimization Layers}},
  author={Agrawal*, Akshay and Amos*, Brandon and Barratt*, Shane and Boyd*, Stephen and Diamond*, Steven and Kolter*, J Zico},
  year={2019},
  booktitle={NeurIPS},
  _venue={NeurIPS},
  url={http://web.stanford.edu/~boyd/papers/pdf/diff_cvxpy.pdf},
  codeurl={https://github.com/cvxgrp/cvxpylayers},
  abstract={
    Recent work has shown how to embed differentiable optimization problems (that is, problems whose solutions can be backpropagated through) as layers within deep learning architectures. This method provides a useful inductive bias for certain problems, but existing software for differentiable optimization layers is rigid and difficult to apply to new settings. In this paper, we propose an approach to differentiating through disciplined convex programs, a subclass of convex optimization problems used by domain-specific languages (DSLs) for convex optimization. We introduce disciplined parametrized programming, a subset of disciplined convex programming, and we show that every disciplined parametrized program can be represented as the composition of an affine map from parameters to problem data, a solver, and an affine map from the solver’s solution to a solution of the original problem (a new form we refer to as affine-solver-affine form). We then demonstrate how to efficiently differentiate through each of these components, allowing for end-to-end analytical differentiation through the entire convex program. We implement our methodology in version 1.1 of CVXPY, a popular Python-embedded DSL for convex optimization, and additionally implement differentiable layers for disciplined convex programs in PyTorch and TensorFlow 2.0. Our implementation significantly lowers the barrier to using convex optimization problems in differentiable programs. We present applications in linear machine learning models and in stochastic control, and we show that our layer is competitive (in execution time) compared to specialized differentiable solvers from past work.
  }
}

@article{grefenstette2019generalized,
  title={{Generalized Inner Loop Meta-Learning}},
  author={Grefenstette, Edward and Amos, Brandon and Yarats, Denis and Htut, Phu Mon and Molchanov, Artem and Meier, Franziska and Kiela, Douwe and Cho, Kyunghyun and Chintala, Soumith},
  journal={arXiv preprint arXiv:1910.01727},
  year={2019},
  _venue={arXiv},
  url={https://arxiv.org/abs/1910.01727},
  codeurl={https://github.com/facebookresearch/higher},
  abstract={
    Many (but not all) approaches self-qualifying as "meta-learning" in
    deep learning and reinforcement learning fit a
    common pattern of approximating the solution to a
    nested optimization problem. In this paper, we give
    a formalization of this shared pattern, which we
    call GIMLI, prove its general requirements, and
    derive a general-purpose algorithm for implementing
    similar approaches. Based on this analysis and
    algorithm, we describe a library of our design,
    higher, which we share with the community to assist
    and enable future research into these kinds of
    meta-learning approaches. We end the paper by
    showcasing the practical applications of this
    framework and library through illustrative
    experiments and ablation studies which they
    facilitate.
  }
}


@article{amos2019limited,
  title={{The Limited Multi-Label Projection Layer}},
  author={Brandon Amos and Vladlen Koltun and J. Zico Kolter},
  journal={arXiv preprint arXiv:1906.08707},
  year={2019},
  _venue={arXiv},
  url={https://arxiv.org/abs/1906.08707},
  codeurl={https://github.com/locuslab/lml},
  abstract={
    We propose the Limited Multi-Label (LML) projection layer as a new
    primitive operation for end-to-end learning systems. The LML layer
    provides a probabilistic way of modeling multi-label predictions
    limited to having exactly k labels. We derive efficient forward and
    backward passes for this layer and show how the layer can be used to
    optimize the top-k recall for multi-label tasks with incomplete label
    information. We evaluate LML layers on top-k CIFAR-100 classification
    and scene graph generation. We show that LML layers add a negligible
    amount of computational overhead, strictly improve the model's
    representational capacity, and improve accuracy. We also revisit the
    truncated top-k entropy method as a competitive baseline for top-k
    classification.
  }
}

@phdthesis{amos2019differentiable,
  author       = {Brandon Amos},
  title        = {{Differentiable Optimization-Based Modeling for Machine Learning}},
  school       = {Carnegie Mellon University},
  year         = 2019,
  _venue = {Ph.D. Thesis},
  codeurl={https://github.com/bamos/thesis},
  url={https://github.com/bamos/thesis/raw/master/bamos_thesis.pdf},
}

@inproceedings{amos2018end,
  title={{{Differentiable MPC for End-to-end Planning and Control}}},
  author={Amos, Brandon and Rodriguez, Ivan Dario Jimenez and Sacks, Jacob and Boots, Byron and Kolter, J Zico},
  year={2018},
  booktitle={NeurIPS},
  _venue={NeurIPS},
  url={https://arxiv.org/abs/1810.13400},
  codeurl={https://locuslab.github.io/mpc.pytorch/},
  abstract={
We present foundations for using Model Predictive Control (MPC) as a differentiable policy class for reinforcement learning in continuous state and action spaces. This provides one way of leveraging and combining the advantages of model-free and model-based approaches. Specifically, we differentiate through MPC by using the KKT conditions of the convex approximation at a fixed point of the controller. Using this strategy, we are able to learn the cost and dynamics of a controller via end-to-end learning. Our experiments focus on imitation learning in the pendulum and cartpole domains, where we learn the cost and dynamics terms of an MPC policy class. We show that our MPC policies are significantly more data-efficient than a generic neural network and that our method is superior to traditional system identification in a setting where the expert is unrealizable.
  }
}

@inproceedings{brown2018depth,
  title={Depth-Limited Solving for Imperfect-Information Games},
  author={Brown, Noam and Sandholm, Tuomas and Amos, Brandon},
  year={2018},
  booktitle={NeurIPS},
  _venue={NeurIPS},
  url={http://arxiv.org/abs/1805.08195},
  abstract={
A fundamental challenge in imperfect-information games is that states do not have well-defined values. As a result, depth-limited search algorithms used in single-agent settings and perfect-information games do not apply. This paper introduces a principled way to conduct depth-limited solving in imperfect-information games by allowing the opponent to choose among a number of strategies for the remainder of the game at the depth limit. Each one of these strategies results in a different set of values for leaf nodes. This forces an agent to be robust to the different strategies an opponent may employ. We demonstrate the effectiveness of this approach by building a master-level heads-up no-limit Texas hold'em poker AI that defeats two prior top agents using only a 4-core CPU and 16 GB of memory. Developing such a powerful agent would have previously required a supercomputer.
  }
}

@inproceedings{amos2018learning,
  title={{{Learning Awareness Models}}},
  author={Brandon Amos and Laurent Dinh and Serkan Cabi and Thomas Roth{\"o}rl and Sergio G{\'o}mez Colmenarejo and Alistair Muldal and Tom Erez and Yuval Tassa and Nando de Freitas and Misha Denil},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=r1HhRfWRZ},
  _venue={ICLR},
  abstract={
    We consider the setting of an agent with a fixed body interacting with an
    unknown and uncertain external world. We show that models
    trained to predict proprioceptive information about the
    agent's body come to represent objects in the external world.
    In spite of being trained with only internally available
    signals, these dynamic body models come to represent external
    objects through the necessity of predicting their effects on
    the agent's own body. That is, the model learns holistic
    persistent representations of objects in the world, even
    though the only training signals are body signals. Our
    dynamics model is able to successfully predict distributions
    over 132 sensor readings over 100 steps into the future and we
    demonstrate that even when the body is no longer in contact
    with an object, the latent variables of the dynamics model
    continue to represent its shape. We show that active data
    collection by maximizing the entropy of predictions about the
    body---touch sensors, proprioception and vestibular
    information---leads to learning of dynamic models that show
    superior performance when used for control. We also collect
    data from a real robotic hand and show that the same models
    can be used to answer questions about properties of objects in
    the real world. Videos with qualitative results of our models
    are available <a href="https://goo.gl/mZuqAV">here</a>.
  }
}

@inproceedings{donti2017task,
  title={{{Task-based End-to-end Model Learning}}},
  author={Donti, Priya L and Amos, Brandon and Kolter, J Zico},
  year={2017},
  booktitle={NeurIPS},
  _venue={NeurIPS},
  codeurl={https://github.com/locuslab/e2e-model-learning},
  url={http://arxiv.org/abs/1703.04529},
  abstract={
    As machine learning techniques have become more ubiquitous, it has
    become common to see machine learning prediction algorithms operating
    within some larger process. However, the criteria by which we train
    machine learning algorithms often differ from the ultimate criteria on
    which we evaluate them. This paper proposes an end-to-end approach for
    learning probabilistic machine learning models within the context of
    stochastic programming, in a manner that directly captures the
    ultimate task-based objective for which they will be used. We then
    present two experimental evaluations of the proposed approach, one as
    applied to a generic inventory stock problem and the second to a
    real-world electrical grid scheduling task. In both cases, we show
    that the proposed approach can outperform both a traditional modeling
    approach and a purely black-box policy optimization approach.
  }
}

@inproceedings{amos2017optnet,
  title = {{{OptNet: Differentiable Optimization as a Layer in Neural Networks}}},
  author={Brandon Amos and J. Zico Kolter},
  booktitle={ICML},
  _venue={ICML},
  codeurl={https://github.com/locuslab/optnet},
  year={2017},
  url={http://arxiv.org/abs/1703.00443},
  abstract={
    This paper presents OptNet, a network architecture that integrates
    optimization problems (here, specifically in the form of quadratic programs)
    as individual layers in larger end-to-end trainable deep networks.
    These layers encode constraints and complex dependencies
    between the hidden states that traditional convolutional and
    fully-connected layers often cannot capture.
    In this paper, we explore the foundations for such an architecture:
    we show how techniques from sensitivity analysis, bilevel
    optimization, and implicit differentiation can be used to
    exactly differentiate through these layers and with respect
    to layer parameters;
    we develop a highly efficient solver for these layers that exploits fast
    GPU-based batch solves within a primal-dual interior point method, and which
    provides backpropagation gradients with virtually no additional cost on top of
    the solve;
    and we highlight the application of these approaches in several problems.
    In one notable example, we show that the method is
    capable of learning to play mini-Sudoku (4x4) given just input and output games,
    with no a priori information about the rules of the game;
    this highlights the ability of our architecture to learn hard
    constraints better than other neural architectures.
  }
}


@inproceedings{amos2017input,
  title={{{Input Convex Neural Networks}}},
  author={Brandon Amos and Lei Xu and J. Zico Kolter},
  booktitle={ICML},
  _venue={ICML},
  codeurl={https://github.com/locuslab/icnn},
  year={2017},
  url={http://arxiv.org/abs/1609.07152},
  abstract={
    This paper presents the input convex neural network
    architecture. These are scalar-valued (potentially deep) neural
    networks with constraints on the network parameters such that the
    output of the network is a convex function of (some of) the inputs.
    The networks allow for efficient inference via optimization over some
    inputs to the network given others, and can be applied to settings
    including structured prediction, data imputation, reinforcement
    learning, and others. In this paper we lay the basic groundwork for
    these models, proposing methods for inference, optimization and
    learning, and analyze their representational power. We show that many
    existing neural network architectures can be made input-convex with
    a minor modification, and develop specialized optimization
    algorithms tailored to this setting. Finally, we highlight the
    performance of the methods on multi-label prediction, image
    completion, and reinforcement learning problems, where we show
    improvement over the existing state of the art in many cases.
  }
}

@inproceedings{zhao2016collapsed,
  title={{{Collapsed Variational Inference for Sum-Product Networks}}},
  author={Han Zhao and Tameem Adel and Geoff Gordon and Brandon Amos},
  booktitle={ICML},
  _venue={ICML},
  year={2016},
  url={http://proceedings.mlr.press/v48/zhaoa16.html},
  abstract={
    Sum-Product Networks (SPNs) are probabilistic inference machines that admit
    exact inference in linear time in the size of the network. Existing
    parameter learning approaches for SPNs are largely based on the maximum
    likelihood principle and hence are subject to overfitting compared to
    more Bayesian approaches. Exact Bayesian posterior inference for SPNs is
    computationally intractable. Both standard variational inference and
    posterior sampling for SPNs are computationally infeasible even for
    networks of moderate size due to the large number of local latent
    variables per instance. In this work, we propose a novel deterministic
    collapsed variational inference algorithm for SPNs that is
    computationally efficient, easy to implement and at the same time allows
    us to incorporate prior information into the optimization formulation.
    Extensive experiments show a significant improvement in accuracy compared
    with a maximum likelihood based approach.
  }
}

@techreport{amos2016openface,
  title={{{OpenFace: A general-purpose face recognition
    library with mobile applications}}},
  author={Amos, Brandon and Bartosz Ludwiczuk and Satyanarayanan, Mahadev},
  _venue={CMU},
  year=2016,
  institution={Technical Report CMU-CS-16-118, CMU School of Computer Science},
  url={http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf},
  codeurl={https://cmusatyalab.github.io/openface},
  abstract={
    Cameras are becoming ubiquitous in the Internet of Things (IoT) and
    can use face recognition technology to improve context. There is a
    large accuracy gap between today's publicly available face recognition
    systems and the state-of-the-art private face recognition
    systems. This paper presents our OpenFace face recognition library
    that bridges this accuracy gap. We show that OpenFace provides
    near-human accuracy on the LFW benchmark and present a new
    classification benchmark for mobile scenarios. This paper is intended
    for non-experts interested in using OpenFace and provides a light
    introduction to the deep neural network techniques we use.

    We released OpenFace in October 2015 as an open source library under
    the Apache 2.0 license. It is available at:
    <http://cmusatyalab.github.io/openface/>
  }
}